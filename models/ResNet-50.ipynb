{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: h5py 3.8.0\n",
      "Uninstalling h5py-3.8.0:\n",
      "  Successfully uninstalled h5py-3.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall --yes h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\python38\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python38\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python38\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python38\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\python38\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python38\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pytorch-lightning 1.6.0 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit_image in c:\\python38\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.21.1 in c:\\python38\\lib\\site-packages (from scikit_image) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\python38\\lib\\site-packages (from scikit_image) (1.10.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\python38\\lib\\site-packages (from scikit_image) (3.0)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\python38\\lib\\site-packages (from scikit_image) (9.5.0)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\python38\\lib\\site-packages (from scikit_image) (2.31.5)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\python38\\lib\\site-packages (from scikit_image) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\python38\\lib\\site-packages (from scikit_image) (1.4.1)\n",
      "Requirement already satisfied: packaging>=21 in c:\\python38\\lib\\site-packages (from scikit_image) (23.1)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in c:\\python38\\lib\\site-packages (from scikit_image) (0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pytorch-lightning 1.6.0 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting h5py\n",
      "  Downloading h5py-3.11.0-cp38-cp38-win_amd64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\python38\\lib\\site-packages (from h5py) (1.24.3)\n",
      "Downloading h5py-3.11.0-cp38-cp38-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/3.0 MB 991.0 kB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.2/3.0 MB 3.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.7/3.0 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.4/3.0 MB 8.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.1/3.0 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.0/3.0 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 10.6 MB/s eta 0:00:00\n",
      "Installing collected packages: h5py\n",
      "Successfully installed h5py-3.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pytorch-lightning 1.6.0 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# DEPENDENCIES ########################################################################################################################################\n",
    "\n",
    "\n",
    "%pip install pandas\n",
    "%pip install scikit_image\n",
    "%pip install h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\python38\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\python38\\lib\\site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\python38\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\python38\\lib\\site-packages (from tensorflow) (23.3.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\python38\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\python38\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\python38\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\python38\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\python38\\lib\\site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\python38\\lib\\site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\python38\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\python38\\lib\\site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\python38\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in c:\\python38\\lib\\site-packages (from tensorflow) (60.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\python38\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\python38\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\python38\\lib\\site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\python38\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\python38\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\python38\\lib\\site-packages (from tensorflow) (1.54.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\python38\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\python38\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\python38\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\python38\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\python38\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\python38\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python38\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\python38\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\python38\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\python38\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\python38\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\python38\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\python38\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (6.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python38\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\python38\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pytorch-lightning 1.6.0 has a non-standard dependency specifier torch>=1.8.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS #############################################################################################################################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau, EarlyStopping, Callback, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS ##########################################################################################################################################\n",
    "\n",
    "\n",
    "# Size of the images\n",
    "img_height, img_width = 48, 48\n",
    "\n",
    "# Parameters\n",
    "num_classes         = 7     # ['Anger', 'Disgust', 'Fear', 'Happiness', 'Sadness', 'Surprise', 'Neutral']\n",
    "epochs_top_layers   = 5\n",
    "epochs_all_layers   = 100\n",
    "batch_size          = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASETS ############################################################################################################################################\n",
    "\n",
    "# Folder where logs and models are stored\n",
    "folder = 'C:/Users/skywalker/Desktop/Meriem_TAIEB_yasmine_MAHDOUI/facial_emotion_recognition/logs/RESNET50'\n",
    "\n",
    "# Data paths\n",
    "train_dataset\t= 'C:/Users/skywalker/Desktop/Meriem_TAIEB_yasmine_MAHDOUI/facial_emotion_recognition/fer2013/train'\n",
    "eval_dataset \t= 'C:/Users/skywalker/Desktop/Meriem_TAIEB_yasmine_MAHDOUI/facial_emotion_recognition/fer2013/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL ###############################################################################################################################################\n",
    "\n",
    "# Create the based on ResNet-50 architecture pre-trained model\n",
    "    # model:        Selects one of the available architectures vgg16, resnet50 or senet50\n",
    "    # include_top:  Whether to include the fully-connected layer at the top of the network\n",
    "    # weights:      Pre-training on VGGFace\n",
    "    # input_shape:  Optional shape tuple, only to be specified if include_top is False (otherwise the input\n",
    "    #               shape has to be (224, 224, 3) (with 'channels_last' data format) or (3, 224, 224) (with\n",
    "    #               'channels_first' data format). It should have exactly 3 inputs channels, and width and\n",
    "    #               height should be no smaller than 197. E.g. (200, 200, 3) would be one valid value.\n",
    "# Returns a keras Model instance\n",
    "base_model = ResNet50(\n",
    "    include_top = False,\n",
    "    weights     = 'imagenet',\n",
    "    input_shape = (img_height, img_width, 3))\n",
    "\n",
    "# Places x as the output of the pre-trained model\n",
    "x = base_model.output\n",
    "\n",
    "# Flattens the input. Does not affect the batch size\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Add a fully-connected layer and a logistic layer\n",
    "# Dense implements the operation: output = activation(dot(input, kernel) + bias(only applicable if use_bias is True))\n",
    "    # units:        Positive integer, dimensionality of the output space\n",
    "    # activation:   Activation function to use\n",
    "    # input shape:  nD tensor with shape: (batch_size, ..., input_dim)\n",
    "    # output shape: nD tensor with shape: (batch_size, ..., units)\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "predictions = Dense(num_classes, activation = 'softmax')(x)\n",
    "\n",
    "# The model we will train\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# # DATA PREPARATION ####################################################################################################################################\n",
    "\n",
    "#create an ImageDataGenerator and generate batches of data\n",
    "def get_datagen(dataset, aug=False):\n",
    "    if aug: #check if augmentation is enabled\n",
    "        datagen = ImageDataGenerator(\n",
    "                            rescale=1./255, #rescale the pixel values to [0,1]\n",
    "                            featurewise_center=False,\n",
    "                            featurewise_std_normalization=False,\n",
    "                            rotation_range=10,  # Randomly rotate images by up to 10 degrees\n",
    "                            width_shift_range=0.1, # Randomly shift images horizontally by up to 10% of the width\n",
    "                            height_shift_range=0.1, # Randomly shift images vertically by up to 10% of the height\n",
    "                            zoom_range=0.1, # Randomly zoom into images by up to 10%\n",
    "                            horizontal_flip=True) #randomly flip images horizontally\n",
    "    else:\n",
    "        datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    return datagen.flow_from_directory(\n",
    "            dataset,\n",
    "            target_size=(197, 197), \n",
    "            color_mode='rgb',\n",
    "            shuffle = True, \n",
    "            class_mode='categorical',\n",
    "            batch_size=batch_size) #size of the batch \n",
    "\n",
    "train_generator  = get_datagen(train_dataset, True)\n",
    "dev_generator    = get_datagen(eval_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/pool1_pad/Pad' defined at (most recent call last):\n    File \"C:\\Python38\\lib\\runpy.py\", line 192, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Python38\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Python38\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Python38\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python38\\lib\\asyncio\\base_events.py\", line 563, in run_forever\n      self._run_once()\n    File \"C:\\Python38\\lib\\asyncio\\base_events.py\", line 1844, in _run_once\n      handle._run()\n    File \"C:\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\skywalker\\AppData\\Local\\Temp\\ipykernel_15616\\1963516963.py\", line 45, in <module>\n      model.fit(\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\layers\\reshaping\\zero_padding2d.py\", line 149, in call\n      return backend.spatial_2d_padding(\n    File \"C:\\Python38\\lib\\site-packages\\keras\\backend.py\", line 4031, in spatial_2d_padding\n      return tf.compat.v1.pad(x, pattern)\nNode: 'model/pool1_pad/Pad'\nOOM when allocating tensor with shape[8192,114,114] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/pool1_pad/Pad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_42027]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m tensorboard_top_layers \u001b[38;5;241m=\u001b[39m TensorBoard(\n\u001b[0;32m     31\u001b[0m \tlog_dir         \u001b[38;5;241m=\u001b[39m folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/logs_top_layers\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     32\u001b[0m \thistogram_freq  \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     33\u001b[0m \twrite_graph     \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     34\u001b[0m \twrite_images    \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Train the model on the new data for a few epochs (Fits the model on data yielded batch-by-batch by a Python generator)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# generator:        A generator or an instance of Sequence (keras.utils.Sequence) object in order to avoid duplicate data when using multiprocessing\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m#                   The output of the generator must be either {a tuple (inputs, targets)} {a tuple (inputs, targets, sample_weights)}\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# callbacks:        List of callbacks to be called during training (to visualize the files created during training, run in your terminal:\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m#                   tensorboard --logdir path_to_current_dir/Graph)\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# samples_per_epoch / batch_size\u001b[39;49;00m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs_top_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                            \u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdev_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtensorboard_top_layers\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/pool1_pad/Pad' defined at (most recent call last):\n    File \"C:\\Python38\\lib\\runpy.py\", line 192, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Python38\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Python38\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Python38\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python38\\lib\\asyncio\\base_events.py\", line 563, in run_forever\n      self._run_once()\n    File \"C:\\Python38\\lib\\asyncio\\base_events.py\", line 1844, in _run_once\n      handle._run()\n    File \"C:\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\skywalker\\AppData\\Local\\Temp\\ipykernel_15616\\1963516963.py\", line 45, in <module>\n      model.fit(\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\layers\\reshaping\\zero_padding2d.py\", line 149, in call\n      return backend.spatial_2d_padding(\n    File \"C:\\Python38\\lib\\site-packages\\keras\\backend.py\", line 4031, in spatial_2d_padding\n      return tf.compat.v1.pad(x, pattern)\nNode: 'model/pool1_pad/Pad'\nOOM when allocating tensor with shape[8192,114,114] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/pool1_pad/Pad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_42027]"
     ]
    }
   ],
   "source": [
    "# UPPER LAYERS TRAINING ###############################################################################################################################\n",
    "\n",
    "# First: train only the top layers (which were randomly initialized) freezing all convolutional ResNet-50 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile (configures the model for training) the model (should be done *AFTER* setting layers to non-trainable)\n",
    "    # optimizer:    String (name of optimizer) or optimizer object\n",
    "        # lr:       Float >= 0. Learning rate\n",
    "        # beta_1:   Float, 0 < beta < 1. Generally close to 1\n",
    "        # beta_2:   Float, 0 < beta < 1. Generally close to 1\n",
    "        # epsilon:  Float >= 0. Fuzz factor\n",
    "        # decay:    Float >= 0. Learning rate decay over each update\n",
    "    # loss:     String (name of objective function) or objective function\n",
    "    # metrics:  List of metrics to be evaluated by the model during training and testing\n",
    "model.compile(\n",
    "    optimizer   = Adam(learning_rate = 1e-3, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08), \n",
    "    loss        = 'categorical_crossentropy', \n",
    "    metrics     = ['accuracy'])\n",
    "\n",
    "# This callback writes a log for TensorBoard, which allows you to visualize dynamic graphs of your training and test metrics, \n",
    "# as well as activation histograms for the different layers in your model\n",
    "    # log_dir:          The path of the directory where to save the log files to be parsed by TensorBoard\n",
    "    # histogram_freq:   Frequency (in epochs) at which to compute activation and weight histograms for the layers of the model\n",
    "    #                   If set to 0, histograms won't be computed. Validation data (or split) must be specified for histogram visualizations\n",
    "    # write_graph:      Whether to visualize the graph in TensorBoard. The log file can become quite large when write_graph is set to True\n",
    "    # write_grads:      Whether to visualize gradient histograms in TensorBoard. histogram_freq must be greater than 0\n",
    "    # write_images:     Whether to write model weights to visualize as image in TensorBoard\n",
    "# To visualize the files created during training, run in your terminal: tensorboard --logdir path_to_current_dir/Graph\n",
    "tensorboard_top_layers = TensorBoard(\n",
    "\tlog_dir         = folder + '/logs_top_layers',\n",
    "\thistogram_freq  = 0,\n",
    "\twrite_graph     = True,\n",
    "\twrite_images    = True)\n",
    "\n",
    "# Train the model on the new data for a few epochs (Fits the model on data yielded batch-by-batch by a Python generator)\n",
    "    # generator:        A generator or an instance of Sequence (keras.utils.Sequence) object in order to avoid duplicate data when using multiprocessing\n",
    "    #                   The output of the generator must be either {a tuple (inputs, targets)} {a tuple (inputs, targets, sample_weights)}\n",
    "    # steps_per_epoch:  Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch\n",
    "    #                   It should typically be equal to the number of unique samples of your dataset divided by the batch size \n",
    "    # epochs:           Integer, total number of iterations on the data\n",
    "    # validation_data:  This can be either {a generator for the validation data } {a tuple (inputs, targets)} {a tuple (inputs, targets, sample_weights)}\n",
    "    # callbacks:        List of callbacks to be called during training (to visualize the files created during training, run in your terminal:\n",
    "    #                   tensorboard --logdir path_to_current_dir/Graph)\n",
    "model.fit(\n",
    "    x           = train_generator,\n",
    "    steps_per_epoch     = len(train_generator), # samples_per_epoch / batch_size\n",
    "    epochs              = epochs_top_layers,                            \n",
    "    validation_data     = dev_generator,\n",
    "    callbacks           = [tensorboard_top_layers]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/conv2_block1_3_bn/FusedBatchNormV3' defined at (most recent call last):\n    File \"C:\\Python38\\lib\\runpy.py\", line 192, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Python38\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Python38\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Python38\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python38\\lib\\asyncio\\base_events.py\", line 563, in run_forever\n      self._run_once()\n    File \"C:\\Python38\\lib\\asyncio\\base_events.py\", line 1844, in _run_once\n      handle._run()\n    File \"C:\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\skywalker\\AppData\\Local\\Temp\\ipykernel_15616\\1162032018.py\", line 65, in <module>\n      model.fit(\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 850, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 660, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"C:\\Python38\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 649, in _fused_batch_norm_inference\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model/conv2_block1_3_bn/FusedBatchNormV3'\nOOM when allocating tensor with shape[128,256,50,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv2_block1_3_bn/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_37038]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[0;32m     50\u001b[0m \tmonitor \t\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     51\u001b[0m \tpatience \t\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     52\u001b[0m \tmode \t\t\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Save the model after every epoch\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \t\u001b[38;5;66;03m# filepath:       String, path to save the model file\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \t\u001b[38;5;66;03m# monitor:        Quantity to monitor {val_loss, val_acc}\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# We train our model again (this time fine-tuning all the resnet blocks)\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# samples_per_epoch / batch_size \u001b[39;49;00m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs_all_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                        \u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdev_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr_plateau\u001b[49m\u001b[43m,\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# SAVING ##############################################################################################################################################\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Saving the model in the workspace\u001b[39;00m\n\u001b[0;32m     75\u001b[0m model\u001b[38;5;241m.\u001b[39msave(folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/ResNet-50.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/conv2_block1_3_bn/FusedBatchNormV3' defined at (most recent call last):\n    File \"C:\\Python38\\lib\\runpy.py\", line 192, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Python38\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Python38\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Python38\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python38\\lib\\asyncio\\base_events.py\", line 563, in run_forever\n      self._run_once()\n    File \"C:\\Python38\\lib\\asyncio\\base_events.py\", line 1844, in _run_once\n      handle._run()\n    File \"C:\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Python38\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\skywalker\\AppData\\Local\\Temp\\ipykernel_15616\\1162032018.py\", line 65, in <module>\n      model.fit(\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 850, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"C:\\Python38\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 660, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"C:\\Python38\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"C:\\Python38\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 649, in _fused_batch_norm_inference\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model/conv2_block1_3_bn/FusedBatchNormV3'\nOOM when allocating tensor with shape[128,256,50,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv2_block1_3_bn/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_37038]"
     ]
    }
   ],
   "source": [
    "# FULL NETWORK TRAINING ###############################################################################################################################\n",
    "\n",
    "# At this point, the top layers are well trained and we can start fine-tuning convolutional layers from ResNet-50\n",
    "\n",
    "\n",
    "# Fine-tuning of all the layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# We need to recompile the model for these modifications to take effect (we use SGD with nesterov momentum and a low learning rate)\n",
    "    # optimizer:    String (name of optimizer) or optimizer object\n",
    "        # lr:       float >= 0. Learning rate\n",
    "        # momentum: float >= 0. Parameter updates momentum\n",
    "        # decay:    float >= 0. Learning rate decay over each update\n",
    "        # nesterov: boolean. Whether to apply Nesterov momentum\n",
    "    # loss:     String (name of objective function) or objective function\n",
    "    # metrics:  List of metrics to be evaluated by the model during training and testing\n",
    "model.compile(\n",
    "    optimizer   = SGD(learning_rate = 1e-4, momentum = 0.9, nesterov = True),\n",
    "    loss        = 'categorical_crossentropy', \n",
    "    metrics     = ['accuracy'])\n",
    "\n",
    "# This callback writes a log for TensorBoard, which allows you to visualize dynamic graphs of your training and test metrics, \n",
    "tensorboard_all_layers = TensorBoard(\n",
    "    log_dir         = folder + '/logs_all_layers',\n",
    "    histogram_freq  = 0,\n",
    "    write_graph     = True,\n",
    "    write_images    = True)\n",
    "\n",
    "# Reduce learning rate when a metric has stopped improving\n",
    "\t# monitor: \tQuantity to be monitored\n",
    "\t# factor: \tFactor by which the learning rate will be reduced. new_lr = lr * factor\n",
    "\t# patience:\tNumber of epochs with no improvement after which learning rate will be reduced\n",
    "\t# mode: \tOne of {auto, min, max}\n",
    "\t# min_lr:\tLower bound on the learning rate\n",
    "reduce_lr_plateau = ReduceLROnPlateau(\n",
    "\tmonitor \t= 'val_acc',\n",
    "\tfactor\t\t= 0.5,\n",
    "\tpatience\t= 3,\n",
    "\tmode \t\t= 'auto',\n",
    "\tmin_lr\t\t= 1e-8)\n",
    "\n",
    "# Stop training when a monitored quantity has stopped improving\n",
    "\t# monitor:\t\tQuantity to be monitored\n",
    "\t# patience:\t\tNumber of epochs with no improvement after which training will be stopped\n",
    "\t# mode: \t\tOne of {auto, min, max}\n",
    "early_stop = EarlyStopping(\n",
    "\tmonitor \t= 'val_acc',\n",
    "\tpatience \t= 10,\n",
    "\tmode \t\t= 'auto')\n",
    "\t\n",
    "\n",
    "# Save the model after every epoch\n",
    "\t# filepath:       String, path to save the model file\n",
    "\t# monitor:        Quantity to monitor {val_loss, val_acc}\n",
    "\t# save_best_only: If save_best_only=True, the latest best model according to the quantity monitored will not be overwritten\n",
    "\t# mode:           One of {auto, min, max}. If save_best_only = True, the decision to overwrite the current save file is made based on either\n",
    "\t#\t\t\t      the maximization or the minimization of the monitored quantity. For val_acc, this should be max, for val_loss this should\n",
    "\t#\t\t\t      be min, etc. In auto mode, the direction is automatically inferred from the name of the monitored quantity\n",
    "\t# period:         Interval (number of epochs) between checkpoints\n",
    "\n",
    "# We train our model again (this time fine-tuning all the resnet blocks)\n",
    "model.fit(\n",
    "    x           = train_generator,\n",
    "    steps_per_epoch     = len(train_generator),  # samples_per_epoch / batch_size \n",
    "    epochs              = epochs_all_layers,                        \n",
    "    validation_data     = dev_generator,\n",
    "    callbacks           = [reduce_lr_plateau,early_stop])\n",
    "\n",
    "# SAVING ##############################################################################################################################################\n",
    "\n",
    "# Saving the model in the workspace\n",
    "model.save(folder + '/ResNet-50.h5')\n",
    "# Save model.h5 on to google storage\n",
    "with file_io.FileIO('ResNet-50.h5', mode='rb') as input_f:\n",
    "    with file_io.FileIO(folder + '/ResNet-50.h5', mode='wb') as output_f:  # w+ : writing and reading\n",
    "        output_f.write(input_f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensorflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtensorflow\u001b[49m\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensorflow' is not defined"
     ]
    }
   ],
   "source": [
    "print(tensorflow.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
