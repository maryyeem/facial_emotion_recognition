{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPENDENCIES ########################################################################################################################################\n",
    "\n",
    "%pip install keras\n",
    "%pip install pandas\n",
    "%pip install scikit_image\n",
    "%pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS #############################################################################################################################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau, EarlyStopping, Callback, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS ##########################################################################################################################################\n",
    "\n",
    "# Size of the images\n",
    "img_height, img_width = 139, 139\n",
    "\n",
    "# Parameters\n",
    "num_classes         = 7     # ['Anger', 'Disgust', 'Fear', 'Happiness', 'Sadness', 'Surprise', 'Neutral']\n",
    "epochs_top_layers   = 5\n",
    "epochs_all_layers   = 100\n",
    "batch_size          = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASETS ############################################################################################################################################\n",
    "\n",
    "# Folder where logs and models are stored\n",
    "folder = 'C:/Users/skywalker/Desktop/Meriem_TAIEB_yasmine_MAHDOUI/facial_emotion_recognition/logs/Inceptionv3'\n",
    "\n",
    "# Data paths\n",
    "train_dataset\t= 'C:/Users/skywalker/Desktop/Meriem_TAIEB_yasmine_MAHDOUI/facial_emotion_recognition/fer2013/train'\n",
    "eval_dataset \t= 'C:/Users/skywalker/Desktop/Meriem_TAIEB_yasmine_MAHDOUI/facial_emotion_recognition/fer2013/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL ###############################################################################################################################################\n",
    "\n",
    "# Create the base pre-trained model\n",
    "    # include_top:  Whether to include the fully-connected layer at the top of the network\n",
    "    # weights:      Pre-training on ImageNet\n",
    "    # input_shape:  Optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (299, 299, 3) \n",
    "    #               (with 'channels_last' data format) or (3, 299, 299) (with 'channels_first' data format). It should have exactly 3 inputs channels, \n",
    "    #               and width and height should be no smaller than 139. E.g. (150, 150, 3) would be one valid value\n",
    "# Returns a keras Model instance\n",
    "base_model = InceptionV3(\n",
    "    include_top = False,\n",
    "    weights     = 'imagenet',\n",
    "    input_shape = (img_height, img_width, 3))\n",
    "\n",
    "# Places x as the output of the pre-trained model\n",
    "x = base_model.output\n",
    "\n",
    "# Add a global spatial average pooling layer\n",
    "    # data_format:  The ordering of the dimensions in the inputs. Default: channels_last (batch, height, width, channels)\n",
    "    # input shape:  4D tensor with shape: (batch_size, rows, cols, channels)\n",
    "    # output shape: 2D tensor with shape: (batch_size, channels) => (None, 2048)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully-connected layer and a logistic layer\n",
    "# Dense implements the operation: output = activation(dot(input, kernel) + bias(only applicable if use_bias is True))\n",
    "    # units:        Positive integer, dimensionality of the output space\n",
    "    # activation:   Activation function to use\n",
    "    # input shape:  nD tensor with shape: (batch_size, ..., input_dim)\n",
    "    # output shape: nD tensor with shape: (batch_size, ..., units)\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "predictions = Dense(num_classes, activation = 'softmax')(x)\n",
    "\n",
    "# The model we will train\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numuber of layers 314\n"
     ]
    }
   ],
   "source": [
    "print('numuber of layers',len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPARATION ####################################################################################################################################\n",
    "\n",
    "# def preprocess_input(x):\n",
    "#     x -= 128.8006 # np.mean(train_dataset)\n",
    "#     return x\n",
    "\n",
    "# # Function that reads the data from the csv file, increases the size of the images and returns the images and their labels\n",
    "#     # dataset: Data path\n",
    "# def get_data(dataset):\n",
    "#     file_stream = file_io.FileIO(dataset, mode='r')\n",
    "#     data = pd.read_csv(file_stream)\n",
    "#     pixels = data['pixels'].tolist()\n",
    "#     images = np.empty((len(data), img_height, img_width, 3))\n",
    "#     i = 0\n",
    "\n",
    "#     for pixel_sequence in pixels:\n",
    "#         single_image = [float(pixel) for pixel in pixel_sequence.split(' ')]  # Extraction of each single\n",
    "#         single_image = np.asarray(single_image).reshape(48, 48) # Dimension: 48x48\n",
    "#         single_image = resize(single_image, (img_height, img_width), order = 3, mode = 'constant') # Dimension: 139x139x3 (Bicubic)\n",
    "#         ret = np.empty((img_height, img_width, 3))  \n",
    "#         ret[:, :, 0] = single_image\n",
    "#         ret[:, :, 1] = single_image\n",
    "#         ret[:, :, 2] = single_image\n",
    "#         images[i, :, :, :] = ret\n",
    "#         i += 1\n",
    "    \n",
    "#     images = preprocess_input(images)\n",
    "#     labels = to_categorical(data['emotion'])\n",
    "\n",
    "#     return images, labels    \n",
    "\n",
    "# # Data preparation\n",
    "# train_data_x, train_data_y  = get_data(train_dataset)\n",
    "# val_data  = get_data(eval_dataset)\n",
    "\n",
    "# # Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches) indefinitely\n",
    "# # rescale:          Rescaling factor (defaults to None). Multiply the data by the value provided (before applying any other transformation)\n",
    "# # rotation_range:   Int. Degree range for random rotations\n",
    "# # shear_range:      Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n",
    "# # zoom_range:       Float or [lower, upper]. Range for random zoom. If a float, [lower, upper] = [1-zoom_range, 1+zoom_range]\n",
    "# # fill_mode :       Points outside the boundaries of the input are filled according to the given mode: {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}\n",
    "# # horizontal_flip:  Boolean. Randomly flip inputs horizontally\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#     rotation_range  = 10,\n",
    "#     shear_range     = 10, # 10 degrees\n",
    "#     zoom_range      = 0.1,\n",
    "#     fill_mode       = 'reflect',\n",
    "#     horizontal_flip = True)\n",
    "\n",
    "# # Takes numpy data & label arrays, and generates batches of augmented/normalized data. Yields batcfillhes indefinitely, in an infinite loop\n",
    "#     # x:            Data. Should have rank 4. In case of grayscale data, the channels axis should have value 1, and in case of RGB data, \n",
    "#     #               it should have value 3\n",
    "#     # y:            Labels\n",
    "#     # batch_size:   Int (default: 32)\n",
    "# train_generator = train_datagen.flow(\n",
    "#     train_data_x,\n",
    "#     train_data_y,\n",
    "#     batch_size  = batch_size)\n",
    "\n",
    "#create an ImageDataGenerator and generate batches of data\n",
    "def get_datagen(dataset, aug=False):\n",
    "    if aug: #check if augmentation is enabled\n",
    "        datagen = ImageDataGenerator(\n",
    "                            rescale=1./255, #rescale the pixel values to [0,1]\n",
    "                            featurewise_center=False,\n",
    "                            featurewise_std_normalization=False,\n",
    "                            rotation_range=10,  # Randomly rotate images by up to 10 degrees\n",
    "                            width_shift_range=0.1, # Randomly shift images horizontally by up to 10% of the width\n",
    "                            height_shift_range=0.1, # Randomly shift images vertically by up to 10% of the height\n",
    "                            zoom_range=0.1, # Randomly zoom into images by up to 10%\n",
    "                            horizontal_flip=True) #randomly flip images horizontally\n",
    "    else:\n",
    "        datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    return datagen.flow_from_directory(\n",
    "            dataset,\n",
    "            target_size=(139, 139), \n",
    "            color_mode='rgb',\n",
    "            shuffle = True, \n",
    "            class_mode='categorical',\n",
    "            batch_size=batch_size) #size of the batch \n",
    "\n",
    "train_generator  = get_datagen(train_dataset, True)\n",
    "dev_generator    = get_datagen(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n"
     ]
    }
   ],
   "source": [
    "print(len(train_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "225/225 [==============================] - 73s 288ms/step - loss: 1.7401 - accuracy: 0.3869 - val_loss: 1.5293 - val_accuracy: 0.4135\n",
      "Epoch 2/5\n",
      "225/225 [==============================] - 61s 271ms/step - loss: 1.4745 - accuracy: 0.4316 - val_loss: 1.4399 - val_accuracy: 0.4500\n",
      "Epoch 3/5\n",
      "225/225 [==============================] - 61s 271ms/step - loss: 1.4353 - accuracy: 0.4477 - val_loss: 1.4608 - val_accuracy: 0.4408\n",
      "Epoch 4/5\n",
      "225/225 [==============================] - 62s 274ms/step - loss: 1.4123 - accuracy: 0.4596 - val_loss: 1.4082 - val_accuracy: 0.4578\n",
      "Epoch 5/5\n",
      "225/225 [==============================] - 61s 270ms/step - loss: 1.3925 - accuracy: 0.4646 - val_loss: 1.3984 - val_accuracy: 0.4631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b3d3fdad90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UPPER LAYERS TRAINING ###############################################################################################################################\n",
    "\n",
    "# First: train only the top layers (which were randomly initialized) freezing all convolutional ResNet50 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile (configures the model for training) the model (should be done *AFTER* setting layers to non-trainable)\n",
    "    # optimizer:    String (name of optimizer) or optimizer object\n",
    "        # lr:       Float >= 0. Learning rate\n",
    "        # beta_1:   Float, 0 < beta < 1. Generally close to 1\n",
    "        # beta_2:   Float, 0 < beta < 1. Generally close to 1\n",
    "        # epsilon:  Float >= 0. Fuzz factor\n",
    "        # decay:    Float >= 0. Learning rate decay over each update\n",
    "    # loss:     String (name of objective function) or objective function\n",
    "    # metrics:  List of metrics to be evaluated by the model during training and testing\n",
    "model.compile(\n",
    "    optimizer   = Adam(learning_rate= 1e-3, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, decay = 0.0), \n",
    "    loss        = 'categorical_crossentropy', \n",
    "    metrics     = ['accuracy'])\n",
    "\n",
    "# This callback writes a log for TensorBoard, which allows you to visualize dynamic graphs of your training and test metrics, \n",
    "# as well as activation histograms for the different layers in your model\n",
    "    # log_dir:          The path of the directory where to save the log files to be parsed by TensorBoard\n",
    "    # histogram_freq:   Frequency (in epochs) at which to compute activation and weight histograms for the layers of the model\n",
    "    #                   If set to 0, histograms won't be computed. Validation data (or split) must be specified for histogram visualizations\n",
    "    # write_graph:      Whether to visualize the graph in TensorBoard. The log file can become quite large when write_graph is set to True\n",
    "    # write_grads:      Whether to visualize gradient histograms in TensorBoard. histogram_freq must be greater than 0\n",
    "    # write_images:     Whether to write model weights to visualize as image in TensorBoard\n",
    "# To visualize the files created during training, run in your terminal: tensorboard --logdir path_to_current_dir/Graph\n",
    "tensorboard_top_layers = TensorBoard(\n",
    "\tlog_dir         = folder + '/logs_top_layers',\n",
    "\thistogram_freq  = 0,\n",
    "\twrite_graph     = True,\n",
    "\twrite_images    = True)\n",
    "\n",
    "# Train the model on the new data for a few epochs (Fits the model on data yielded batch-by-batch by a Python generator)\n",
    "    # generator:        A generator or an instance of Sequence (keras.utils.Sequence) object in order to avoid duplicate data when using multiprocessing\n",
    "    #                   The output of the generator must be either {a tuple (inputs, targets)} {a tuple (inputs, targets, sample_weights)}\n",
    "    # steps_per_epoch:  Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch\n",
    "    #                   It should typically be equal to the number of unique samples of your dataset divided by the batch size \n",
    "    # epochs:           Integer, total number of iterations on the data\n",
    "    # validation_data:  This can be either {a generator for the validation data } {a tuple (inputs, targets)} {a tuple (inputs, targets, sample_weights)}\n",
    "    # callbacks:        List of callbacks to be called during training (to visualize the files created during training, run in your terminal:\n",
    "    #                   tensorboard --logdir path_to_current_dir/Graph)\n",
    "model.fit(\n",
    "    x          = train_generator,\n",
    "    steps_per_epoch     = len(train_generator),  # samples_per_epoch / batch_size\n",
    "    epochs              = epochs_top_layers,                            \n",
    "    validation_data     = dev_generator,\n",
    "    callbacks           = [tensorboard_top_layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.7760 - accuracy: 0.2682WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 161s 660ms/step - loss: 1.7760 - accuracy: 0.2682 - val_loss: 1.6970 - val_accuracy: 0.3068 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.6932 - accuracy: 0.3242WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 145s 645ms/step - loss: 1.6932 - accuracy: 0.3242 - val_loss: 1.6327 - val_accuracy: 0.3541 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.6382 - accuracy: 0.3473WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 145s 644ms/step - loss: 1.6382 - accuracy: 0.3473 - val_loss: 1.6134 - val_accuracy: 0.3672 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.5919 - accuracy: 0.3711WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 145s 644ms/step - loss: 1.5919 - accuracy: 0.3711 - val_loss: 1.5454 - val_accuracy: 0.3968 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.5503 - accuracy: 0.3913WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 145s 644ms/step - loss: 1.5503 - accuracy: 0.3913 - val_loss: 1.4962 - val_accuracy: 0.4143 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.5103 - accuracy: 0.4140WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 145s 641ms/step - loss: 1.5103 - accuracy: 0.4140 - val_loss: 1.4702 - val_accuracy: 0.4296 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.4814 - accuracy: 0.4279WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 144s 640ms/step - loss: 1.4814 - accuracy: 0.4279 - val_loss: 1.4396 - val_accuracy: 0.4450 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.4507 - accuracy: 0.4399WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 144s 640ms/step - loss: 1.4507 - accuracy: 0.4399 - val_loss: 1.4094 - val_accuracy: 0.4581 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.4202 - accuracy: 0.4536WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 144s 640ms/step - loss: 1.4202 - accuracy: 0.4536 - val_loss: 1.3890 - val_accuracy: 0.4642 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.3949 - accuracy: 0.4655WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 144s 641ms/step - loss: 1.3949 - accuracy: 0.4655 - val_loss: 1.3722 - val_accuracy: 0.4728 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.3743 - accuracy: 0.4735WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 144s 640ms/step - loss: 1.3743 - accuracy: 0.4735 - val_loss: 1.3594 - val_accuracy: 0.4739 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.3539 - accuracy: 0.4807WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 144s 640ms/step - loss: 1.3539 - accuracy: 0.4807 - val_loss: 1.3485 - val_accuracy: 0.4798 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.3334 - accuracy: 0.4905WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 144s 639ms/step - loss: 1.3334 - accuracy: 0.4905 - val_loss: 1.3380 - val_accuracy: 0.4817 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.3166 - accuracy: 0.4959WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 144s 637ms/step - loss: 1.3166 - accuracy: 0.4959 - val_loss: 1.3145 - val_accuracy: 0.4826 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.3009 - accuracy: 0.5006WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 144s 638ms/step - loss: 1.3009 - accuracy: 0.5006 - val_loss: 1.3141 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.2897 - accuracy: 0.5055WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 144s 638ms/step - loss: 1.2897 - accuracy: 0.5055 - val_loss: 1.3087 - val_accuracy: 0.4968 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.2740 - accuracy: 0.5101WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 144s 638ms/step - loss: 1.2740 - accuracy: 0.5101 - val_loss: 1.2863 - val_accuracy: 0.5057 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.2588 - accuracy: 0.5167WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 144s 638ms/step - loss: 1.2588 - accuracy: 0.5167 - val_loss: 1.2652 - val_accuracy: 0.5099 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.2485 - accuracy: 0.5232WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 144s 638ms/step - loss: 1.2485 - accuracy: 0.5232 - val_loss: 1.2553 - val_accuracy: 0.5143 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.2349 - accuracy: 0.5269WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 144s 638ms/step - loss: 1.2349 - accuracy: 0.5269 - val_loss: 1.2441 - val_accuracy: 0.5143 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.2222 - accuracy: 0.5318WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 144s 638ms/step - loss: 1.2222 - accuracy: 0.5318 - val_loss: 1.2389 - val_accuracy: 0.5141 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.2170 - accuracy: 0.5307WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 144s 638ms/step - loss: 1.2170 - accuracy: 0.5307 - val_loss: 1.2327 - val_accuracy: 0.5169 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.2055 - accuracy: 0.5383WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 144s 638ms/step - loss: 1.2055 - accuracy: 0.5383 - val_loss: 1.2392 - val_accuracy: 0.5171 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.1939 - accuracy: 0.5427WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 144s 638ms/step - loss: 1.1939 - accuracy: 0.5427 - val_loss: 1.2109 - val_accuracy: 0.5283 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.1850 - accuracy: 0.5479WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 142s 631ms/step - loss: 1.1850 - accuracy: 0.5479 - val_loss: 1.2313 - val_accuracy: 0.5208 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.1715 - accuracy: 0.5478WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 141s 626ms/step - loss: 1.1715 - accuracy: 0.5478 - val_loss: 1.1973 - val_accuracy: 0.5352 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.1652 - accuracy: 0.5513WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 141s 626ms/step - loss: 1.1652 - accuracy: 0.5513 - val_loss: 1.1951 - val_accuracy: 0.5313 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.1535 - accuracy: 0.5553WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 141s 624ms/step - loss: 1.1535 - accuracy: 0.5553 - val_loss: 1.2067 - val_accuracy: 0.5258 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.1495 - accuracy: 0.5589WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 141s 624ms/step - loss: 1.1495 - accuracy: 0.5589 - val_loss: 1.1854 - val_accuracy: 0.5358 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.1367 - accuracy: 0.5626WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 141s 625ms/step - loss: 1.1367 - accuracy: 0.5626 - val_loss: 1.1727 - val_accuracy: 0.5408 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.1295 - accuracy: 0.5701WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 141s 625ms/step - loss: 1.1295 - accuracy: 0.5701 - val_loss: 1.1818 - val_accuracy: 0.5403 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.1224 - accuracy: 0.5705WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "225/225 [==============================] - 141s 624ms/step - loss: 1.1224 - accuracy: 0.5705 - val_loss: 1.1689 - val_accuracy: 0.5436 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      " 85/225 [==========>...................] - ETA: 1:26 - loss: 1.1203 - accuracy: 0.5718"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# We train our model again (this time fine-tuning all the inception blocks)\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# samples_per_epoch / batch_size\u001b[39;49;00m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs_all_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdev_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# SAVING ##############################################################################################################################################\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Saving the model in the workspace\u001b[39;00m\n\u001b[0;32m     75\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInception-v3.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# FULL NETWORK TRAINING ###############################################################################################################################\n",
    "\n",
    "# At this point, the top layers are well trained and we can start fine-tuning convolutional layers from Inception-v3\n",
    "\n",
    "# Fine-tuning of all the layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# We need to recompile the model for these modifications to take effect (we use SGD with nesterov momentum and a low learning rate)\n",
    "    # optimizer:    String (name of optimizer) or optimizer object\n",
    "        # lr:       float >= 0. Learning rate\n",
    "        # momentum: float >= 0. Parameter updates momentum\n",
    "        # decay:    float >= 0. Learning rate decay over each update\n",
    "        # nesterov: boolean. Whether to apply Nesterov momentum\n",
    "    # loss:     String (name of objective function) or objective function\n",
    "    # metrics:  List of metrics to be evaluated by the model during training and testing\n",
    "model.compile(\n",
    "    optimizer   = SGD(learning_rate= 1e-4, momentum = 0.9, nesterov = True),\n",
    "    loss        = 'categorical_crossentropy', \n",
    "    metrics     = ['accuracy'])\n",
    "\n",
    "# This callback writes a log for TensorBoard, which allows you to visualize dynamic graphs of your training and test metrics, \n",
    "tensorboard_all_layers = TensorBoard(\n",
    "    log_dir         = folder + '/logs_all_layers',\n",
    "    histogram_freq  = 0,\n",
    "    write_graph     = True,\n",
    "    write_images    = True)\n",
    "\n",
    "# Reduce learning rate when a metric has stopped improving\n",
    "\t# monitor: \tQuantity to be monitored\n",
    "\t# factor: \tFactor by which the learning rate will be reduced. new_lr = lr * factor\n",
    "\t# patience:\tNumber of epochs with no improvement after which learning rate will be reduced\n",
    "\t# mode: \tOne of {auto, min, max}\n",
    "\t# min_lr:\tLower bound on the learning rate\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "\tmonitor \t= 'val_acc',\n",
    "\tfactor\t\t= 0.4,\n",
    "\tpatience\t= 5,\n",
    "\tmode \t\t= 'auto',\n",
    "\tmin_lr\t\t= 1e-6)\n",
    "\n",
    "# Stop training when a monitored quantity has stopped improving\n",
    "\t# monitor:\t\tQuantity to be monitored\n",
    "\t# patience:\t\tNumber of epochs with no improvement after which training will be stopped\n",
    "\t# mode: \t\tOne of {auto, min, max}\n",
    "early_stop = EarlyStopping(\n",
    "\tmonitor \t= 'val_acc',\n",
    "\tpatience \t= 20,\n",
    "\tmode \t\t= 'auto')\n",
    "\n",
    "\n",
    "# Save the model after every epoch\n",
    "\t# filepath:       String, path to save the model file\n",
    "\t# monitor:        Quantity to monitor {val_loss, val_acc}\n",
    "\t# save_best_only: If save_best_only=True, the latest best model according to the quantity monitored will not be overwritten\n",
    "\t# mode:           One of {auto, min, max}. If save_best_only = True, the decision to overwrite the current save file is made based on either\n",
    "\t#\t\t\t      the maximization or the minimization of the monitored quantity. For val_acc, this should be max, for val_loss this should\n",
    "\t#\t\t\t      be min, etc. In auto mode, the direction is automatically inferred from the name of the monitored quantity\n",
    "\t# period:         Interval (number of epochs) between checkpoints\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "# We train our model again (this time fine-tuning all the inception blocks)\n",
    "model.fit(\n",
    "    x           = train_generator,\n",
    "    steps_per_epoch     = len(train_generator),  # samples_per_epoch / batch_size\n",
    "    epochs              = epochs_all_layers,\n",
    "    validation_data     = dev_generator,\n",
    "    callbacks           = [reduce_lr, early_stop])\n",
    "\n",
    "# SAVING ##############################################################################################################################################\n",
    "\n",
    "# Saving the model in the workspace\n",
    "model.save('Inception-v3.h5')\n",
    "with file_io.FileIO('Inception-v3.h5', mode='rb') as input_f:\n",
    "    with file_io.FileIO(folder + '/Inception-v3.h5', mode='wb') as output_f:  # w+ : writing and reading\n",
    "        output_f.write(input_f.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
